7767517
88 92
Input            input_1__0               0 1 input_1__0
Convolution      convolution              1 1 input_1__0 Conv1_convolution_0 0=32 1=3 11=3 2=1 12=1 3=2 13=2 4=0 14=0 15=1 16=1 5=0 6=864
BatchNorm        batchnorm                1 1 Conv1_convolution_0 bn_Conv1_FusedBatchNorm_1_0 0=32
ReLU             activation               1 1 bn_Conv1_FusedBatchNorm_1_0 Conv1_relu_Relu_0
ConvolutionDepthWise convolution1             1 1 Conv1_relu_Relu_0 expanded_conv_depthwise_depthwise_0 0=32 1=3 11=3 2=1 12=1 3=1 13=1 4=-233 5=0 6=288 7=32
BatchNorm        batchnorm1               1 1 expanded_conv_depthwise_depthwise_0 expanded_conv_depthwise_BN_FusedBatchNorm_1_0 0=32
ReLU             activation1              1 1 expanded_conv_depthwise_BN_FusedBatchNorm_1_0 expanded_conv_depthwise_relu_Relu_0
Convolution      convolution2             1 1 expanded_conv_depthwise_relu_Relu_0 expanded_conv_project_convolution_0 0=16 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=512
BatchNorm        batchnorm2               1 1 expanded_conv_project_convolution_0 expanded_conv_project_BN_FusedBatchNorm_1_0 0=16
Convolution      convolution3             1 1 expanded_conv_project_BN_FusedBatchNorm_1_0 block_1_expand_convolution_0 0=96 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=1536
BatchNorm        batchnorm3               1 1 block_1_expand_convolution_0 block_1_expand_BN_FusedBatchNorm_1_0 0=96
ReLU             activation2              1 1 block_1_expand_BN_FusedBatchNorm_1_0 block_1_expand_relu_Relu_0
ConvolutionDepthWise convolution4             1 1 block_1_expand_relu_Relu_0 block_1_depthwise_depthwise_0 0=96 1=3 11=3 2=1 12=1 3=2 13=2 4=0 14=0 15=1 16=1 5=0 6=864 7=96
BatchNorm        batchnorm4               1 1 block_1_depthwise_depthwise_0 block_1_depthwise_BN_FusedBatchNorm_1_0 0=96
ReLU             activation3              1 1 block_1_depthwise_BN_FusedBatchNorm_1_0 block_1_depthwise_relu_Relu_0
Convolution      convolution5             1 1 block_1_depthwise_relu_Relu_0 block_1_project_convolution_0 0=24 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=2304
BatchNorm        batchnorm5               1 1 block_1_project_convolution_0 block_1_project_BN_FusedBatchNorm_1_0 0=24
Split            splitncnn_0              1 2 block_1_project_BN_FusedBatchNorm_1_0 block_1_project_BN_FusedBatchNorm_1_0_splitncnn_0 block_1_project_BN_FusedBatchNorm_1_0_splitncnn_1
Convolution      convolution6             1 1 block_1_project_BN_FusedBatchNorm_1_0_splitncnn_1 block_2_expand_convolution_0 0=144 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=3456
BatchNorm        batchnorm6               1 1 block_2_expand_convolution_0 block_2_expand_BN_FusedBatchNorm_1_0 0=144
ReLU             activation4              1 1 block_2_expand_BN_FusedBatchNorm_1_0 block_2_expand_relu_Relu_0
ConvolutionDepthWise convolution7             1 1 block_2_expand_relu_Relu_0 block_2_depthwise_depthwise_0 0=144 1=3 11=3 2=1 12=1 3=1 13=1 4=-233 5=0 6=1296 7=144
BatchNorm        batchnorm7               1 1 block_2_depthwise_depthwise_0 block_2_depthwise_BN_FusedBatchNorm_1_0 0=144
ReLU             activation5              1 1 block_2_depthwise_BN_FusedBatchNorm_1_0 block_2_depthwise_relu_Relu_0
Convolution      convolution8             1 1 block_2_depthwise_relu_Relu_0 block_2_project_convolution_0 0=24 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=3456
BatchNorm        batchnorm8               1 1 block_2_project_convolution_0 block_2_project_BN_FusedBatchNorm_1_0 0=24
BinaryOp         add                      2 1 block_1_project_BN_FusedBatchNorm_1_0_splitncnn_0 block_2_project_BN_FusedBatchNorm_1_0 block_2_add_add_0 0=0
Convolution      convolution9             1 1 block_2_add_add_0 block_3_expand_convolution_0 0=144 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=3456
BatchNorm        batchnorm9               1 1 block_3_expand_convolution_0 block_3_expand_BN_FusedBatchNorm_1_0 0=144
ReLU             activation6              1 1 block_3_expand_BN_FusedBatchNorm_1_0 block_3_expand_relu_Relu_0
ConvolutionDepthWise convolution10            1 1 block_3_expand_relu_Relu_0 block_3_depthwise_depthwise_0 0=144 1=3 11=3 2=1 12=1 3=2 13=2 4=0 14=0 15=1 16=1 5=0 6=1296 7=144
BatchNorm        batchnorm10              1 1 block_3_depthwise_depthwise_0 block_3_depthwise_BN_FusedBatchNorm_1_0 0=144
ReLU             activation7              1 1 block_3_depthwise_BN_FusedBatchNorm_1_0 block_3_depthwise_relu_Relu_0
Convolution      convolution11            1 1 block_3_depthwise_relu_Relu_0 block_3_project_convolution_0 0=32 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=4608
BatchNorm        batchnorm11              1 1 block_3_project_convolution_0 block_3_project_BN_FusedBatchNorm_1_0 0=32
Split            splitncnn_1              1 2 block_3_project_BN_FusedBatchNorm_1_0 block_3_project_BN_FusedBatchNorm_1_0_splitncnn_0 block_3_project_BN_FusedBatchNorm_1_0_splitncnn_1
Convolution      convolution12            1 1 block_3_project_BN_FusedBatchNorm_1_0_splitncnn_1 block_4_expand_convolution_0 0=192 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=6144
BatchNorm        batchnorm12              1 1 block_4_expand_convolution_0 block_4_expand_BN_FusedBatchNorm_1_0 0=192
ReLU             activation8              1 1 block_4_expand_BN_FusedBatchNorm_1_0 block_4_expand_relu_Relu_0
ConvolutionDepthWise convolution13            1 1 block_4_expand_relu_Relu_0 block_4_depthwise_depthwise_0 0=192 1=3 11=3 2=1 12=1 3=1 13=1 4=-233 5=0 6=1728 7=192
BatchNorm        batchnorm13              1 1 block_4_depthwise_depthwise_0 block_4_depthwise_BN_FusedBatchNorm_1_0 0=192
ReLU             activation9              1 1 block_4_depthwise_BN_FusedBatchNorm_1_0 block_4_depthwise_relu_Relu_0
Convolution      convolution14            1 1 block_4_depthwise_relu_Relu_0 block_4_project_convolution_0 0=32 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=6144
BatchNorm        batchnorm14              1 1 block_4_project_convolution_0 block_4_project_BN_FusedBatchNorm_1_0 0=32
BinaryOp         add1                     2 1 block_3_project_BN_FusedBatchNorm_1_0_splitncnn_0 block_4_project_BN_FusedBatchNorm_1_0 block_4_add_add_0 0=0
Split            splitncnn_2              1 2 block_4_add_add_0 block_4_add_add_0_splitncnn_0 block_4_add_add_0_splitncnn_1
Convolution      convolution15            1 1 block_4_add_add_0_splitncnn_1 block_5_expand_convolution_0 0=192 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=6144
BatchNorm        batchnorm15              1 1 block_5_expand_convolution_0 block_5_expand_BN_FusedBatchNorm_1_0 0=192
ReLU             activation10             1 1 block_5_expand_BN_FusedBatchNorm_1_0 block_5_expand_relu_Relu_0
ConvolutionDepthWise convolution16            1 1 block_5_expand_relu_Relu_0 block_5_depthwise_depthwise_0 0=192 1=3 11=3 2=1 12=1 3=1 13=1 4=-233 5=0 6=1728 7=192
BatchNorm        batchnorm16              1 1 block_5_depthwise_depthwise_0 block_5_depthwise_BN_FusedBatchNorm_1_0 0=192
ReLU             activation11             1 1 block_5_depthwise_BN_FusedBatchNorm_1_0 block_5_depthwise_relu_Relu_0
Convolution      convolution17            1 1 block_5_depthwise_relu_Relu_0 block_5_project_convolution_0 0=32 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=6144
BatchNorm        batchnorm17              1 1 block_5_project_convolution_0 block_5_project_BN_FusedBatchNorm_1_0 0=32
BinaryOp         add2                     2 1 block_4_add_add_0_splitncnn_0 block_5_project_BN_FusedBatchNorm_1_0 block_5_add_add_0 0=0
Convolution      convolution18            1 1 block_5_add_add_0 block_6_expand_convolution_0 0=192 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=6144
BatchNorm        batchnorm18              1 1 block_6_expand_convolution_0 block_6_expand_BN_FusedBatchNorm_1_0 0=192
ReLU             activation12             1 1 block_6_expand_BN_FusedBatchNorm_1_0 block_6_expand_relu_Relu_0
ConvolutionDepthWise convolution19            1 1 block_6_expand_relu_Relu_0 block_6_depthwise_depthwise_0 0=192 1=3 11=3 2=1 12=1 3=2 13=2 4=0 14=0 15=1 16=1 5=0 6=1728 7=192
BatchNorm        batchnorm19              1 1 block_6_depthwise_depthwise_0 block_6_depthwise_BN_FusedBatchNorm_1_0 0=192
ReLU             activation13             1 1 block_6_depthwise_BN_FusedBatchNorm_1_0 block_6_depthwise_relu_Relu_0
Convolution      convolution20            1 1 block_6_depthwise_relu_Relu_0 block_6_project_convolution_0 0=64 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=12288
BatchNorm        batchnorm20              1 1 block_6_project_convolution_0 block_6_project_BN_FusedBatchNorm_1_0 0=64
Split            splitncnn_3              1 2 block_6_project_BN_FusedBatchNorm_1_0 block_6_project_BN_FusedBatchNorm_1_0_splitncnn_0 block_6_project_BN_FusedBatchNorm_1_0_splitncnn_1
Convolution      convolution21            1 1 block_6_project_BN_FusedBatchNorm_1_0_splitncnn_1 block_7_expand_convolution_0 0=384 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=24576
BatchNorm        batchnorm21              1 1 block_7_expand_convolution_0 block_7_expand_BN_FusedBatchNorm_1_0 0=384
ReLU             activation14             1 1 block_7_expand_BN_FusedBatchNorm_1_0 block_7_expand_relu_Relu_0
ConvolutionDepthWise convolution22            1 1 block_7_expand_relu_Relu_0 block_7_depthwise_depthwise_0 0=384 1=3 11=3 2=1 12=1 3=1 13=1 4=-233 5=0 6=3456 7=384
BatchNorm        batchnorm22              1 1 block_7_depthwise_depthwise_0 block_7_depthwise_BN_FusedBatchNorm_1_0 0=384
ReLU             activation15             1 1 block_7_depthwise_BN_FusedBatchNorm_1_0 block_7_depthwise_relu_Relu_0
Convolution      convolution23            1 1 block_7_depthwise_relu_Relu_0 block_7_project_convolution_0 0=64 1=1 11=1 2=1 12=1 3=1 13=1 4=-233 5=0 6=24576
BatchNorm        batchnorm23              1 1 block_7_project_convolution_0 block_7_project_BN_FusedBatchNorm_1_0 0=64
BinaryOp         add3                     2 1 block_6_project_BN_FusedBatchNorm_1_0_splitncnn_0 block_7_project_BN_FusedBatchNorm_1_0 block_7_add_add_0 0=0
ConvolutionDepthWise convolution24            1 1 block_7_add_add_0 separable_conv2d_1_separable_conv2d_depthwise_0 0=64 1=3 11=3 2=1 12=1 3=2 13=2 5=0 6=576 7=64
Convolution      convolution25            1 1 separable_conv2d_1_separable_conv2d_depthwise_0 separable_conv2d_1_separable_conv2d_0 0=128 1=1 11=1 2=1 12=1 3=1 13=1 5=0 6=8192
BatchNorm        batchnorm24              1 1 separable_conv2d_1_separable_conv2d_0 separable_conv2d_1_BiasAdd_0 0=128
ReLU             activation16             1 1 separable_conv2d_1_BiasAdd_0 separable_conv2d_1_Relu_0
BatchNorm        batchnorm25              1 1 separable_conv2d_1_Relu_0 batch_normalization_1_FusedBatchNorm_1_0 0=128
ConvolutionDepthWise convolution26            1 1 batch_normalization_1_FusedBatchNorm_1_0 separable_conv2d_2_separable_conv2d_depthwise_0 0=128 1=3 11=3 2=1 12=1 3=2 13=2 5=0 6=1152 7=128
Convolution      convolution27            1 1 separable_conv2d_2_separable_conv2d_depthwise_0 separable_conv2d_2_separable_conv2d_0 0=256 1=1 11=1 2=1 12=1 3=1 13=1 5=0 6=32768
BatchNorm        batchnorm26              1 1 separable_conv2d_2_separable_conv2d_0 separable_conv2d_2_BiasAdd_0 0=256
ReLU             activation17             1 1 separable_conv2d_2_BiasAdd_0 separable_conv2d_2_Relu_0
Reshape          Reshape                  1 1 separable_conv2d_2_Relu_0 separable_conv2d_2_Relu_0_reshaped 0=256
InnerProduct     innerProduct             1 1 separable_conv2d_2_Relu_0_reshaped innerProduct_buffer 0=512 1=1 2=131072
Reshape          Reshape1                 1 1 innerProduct_buffer dense_1_BiasAdd_0 0=1 1=1 2=512
Reshape          Reshape2                 1 1 dense_1_BiasAdd_0 dense_1_BiasAdd_0_reshaped 0=512
InnerProduct     innerProduct1            1 1 dense_1_BiasAdd_0_reshaped innerProduct1_buffer 0=196 1=1 2=100352
Reshape          Reshape3                 1 1 innerProduct1_buffer face_output_0__0 0=1 1=1 2=196